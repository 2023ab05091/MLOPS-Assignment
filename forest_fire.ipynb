{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1ac5aa-1283-44d2-9f28-2305dda89424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.20.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting mlflow-skinny==2.20.0 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.20.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow) (3.0.3)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow) (3.1.4)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow) (3.4.1)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow) (3.8.4)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow) (2.2.2)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow) (14.0.2)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow) (1.4.2)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow) (1.13.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow) (2.0.30)\n",
      "Collecting waitress<4 (from mlflow)\n",
      "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (2.2.1)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.20.0->mlflow)\n",
      "  Downloading databricks_sdk-0.41.0-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (3.1.37)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (7.0.1)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.20.0->mlflow)\n",
      "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.20.0->mlflow)\n",
      "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (23.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (3.20.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (2.10.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (2.32.2)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.20.0->mlflow)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.20.0->mlflow) (4.12.2)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (305.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (1.6.2)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (2.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.20.0->mlflow) (0.4.6)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.0->mlflow)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.0->mlflow) (4.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.0->mlflow) (3.17.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.0->mlflow)\n",
      "  Downloading Deprecated-1.2.17-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.0->mlflow)\n",
      "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.0->mlflow-skinny==2.20.0->mlflow) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.0->mlflow-skinny==2.20.0->mlflow) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.0->mlflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.0->mlflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.0->mlflow) (2024.12.14)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.0->mlflow) (1.14.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.0->mlflow) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.0->mlflow) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.0->mlflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sumis\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.0->mlflow) (0.4.8)\n",
      "Downloading mlflow-2.20.0-py3-none-any.whl (28.3 MB)\n",
      "   ---------------------------------------- 0.0/28.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/28.3 MB 34.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 5.5/28.3 MB 58.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 9.6/28.3 MB 68.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 13.6/28.3 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 17.6/28.3 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 21.7/28.3 MB 81.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.9/28.3 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.3/28.3 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.3/28.3 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.3/28.3 MB 54.7 MB/s eta 0:00:00\n",
      "Downloading mlflow_skinny-2.20.0-py3-none-any.whl (6.0 MB)\n",
      "   ---------------------------------------- 0.0/6.0 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 3.7/6.0 MB 77.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.0/6.0 MB 76.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.0/6.0 MB 64.2 MB/s eta 0:00:00\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 233.6/233.6 kB 14.0 MB/s eta 0:00:00\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 0.0/147.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 147.8/147.8 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "   ---------------------------------------- 0.0/114.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 114.9/114.9 kB ? eta 0:00:00\n",
      "Downloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.2/56.2 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading databricks_sdk-0.41.0-py3-none-any.whl (637 kB)\n",
      "   ---------------------------------------- 0.0/637.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 637.5/637.5 kB 39.2 MB/s eta 0:00:00\n",
      "Downloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "   ---------------------------------------- 0.0/203.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 203.2/203.2 kB 12.1 MB/s eta 0:00:00\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_api-1.29.0-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.3/64.3 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl (118 kB)\n",
      "   ---------------------------------------- 0.0/118.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 118.1/118.1 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 0.0/166.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 166.6/166.6 kB 10.4 MB/s eta 0:00:00\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB ? eta 0:00:00\n",
      "Downloading Deprecated-1.2.17-py2.py3-none-any.whl (9.1 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "   ---------------------------------------- 0.0/210.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 210.8/210.8 kB ? eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: waitress, sqlparse, rsa, Mako, graphql-core, deprecated, opentelemetry-api, graphql-relay, google-auth, docker, alembic, opentelemetry-semantic-conventions, graphene, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Mako-1.3.8 alembic-1.14.1 databricks-sdk-0.41.0 deprecated-1.2.17 docker-7.1.0 google-auth-2.38.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 mlflow-2.20.0 mlflow-skinny-2.20.0 opentelemetry-api-1.29.0 opentelemetry-sdk-1.29.0 opentelemetry-semantic-conventions-0.50b0 rsa-4.9 sqlparse-0.5.3 waitress-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c18988-c950-4c9d-adf4-423a9a5bebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a99671-7e33-4cce-a7df-904238b677d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and tuning LogisticRegression...\n",
      "Best Parameters for LogisticRegression: {'C': 3.845401188473625, 'max_iter': 448, 'solver': 'lbfgs'}\n",
      "Accuracy: 1.0000, F1-score: 1.0000\n",
      "Training and tuning RandomForest...\n",
      "Best Parameters for RandomForest: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 18}\n",
      "Accuracy: 0.9167, F1-score: 0.9172\n",
      "Training and tuning SVM...\n",
      "Best Parameters for SVM: {'C': 3.845401188473625, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Accuracy: 1.0000, F1-score: 1.0000\n",
      "Training and tuning KNN...\n",
      "Best Parameters for KNN: {'n_neighbors': 4, 'weights': 'distance'}\n",
      "Accuracy: 0.9167, F1-score: 0.9148\n",
      "\n",
      "Comparison of Models:\n",
      "                Model                                         Best Model  \\\n",
      "0  LogisticRegression  LogisticRegression(C=3.845401188473625, max_it...   \n",
      "1        RandomForest  (DecisionTreeClassifier(criterion='entropy', m...   \n",
      "2                 SVM          SVC(C=3.845401188473625, kernel='linear')   \n",
      "3                 KNN  KNeighborsClassifier(n_neighbors=4, weights='d...   \n",
      "\n",
      "                                     Best Parameters  Accuracy  F1 Score  \n",
      "0  {'C': 3.845401188473625, 'max_iter': 448, 'sol...  1.000000  1.000000  \n",
      "1  {'criterion': 'entropy', 'max_depth': None, 'm...  0.916667  0.917249  \n",
      "2  {'C': 3.845401188473625, 'gamma': 'scale', 'ke...  1.000000  1.000000  \n",
      "3          {'n_neighbors': 4, 'weights': 'distance'}  0.916667  0.914815  \n",
      "\n",
      "Best Model: LogisticRegression\n",
      "Accuracy: 1.0000, F1 Score: 1.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37af68f3653400f9e1c27944933e610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model logged to MLflow successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Forest_Fire_Best_Model' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'Forest_Fire_Best_Model'.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from scipy.stats import randint, uniform\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Forest_fire.csv\").to_numpy()\n",
    "\n",
    "X = data[1:, 1:-1].astype('int')  # Features\n",
    "y = data[1:, -1].astype('int')    # Target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define models and their parameter distributions for RandomizedSearchCV\n",
    "models = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'solver': ['lbfgs', 'liblinear'],\n",
    "            'max_iter': randint(100, 500),  # Max iterations\n",
    "            'C': uniform(0.1, 10.0)        # Regularization strength\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': randint(10, 200),       # Number of trees\n",
    "            'max_depth': [None, 10, 20, 30],       # Maximum tree depth\n",
    "            'criterion': ['gini', 'entropy'],      # Splitting criterion\n",
    "            'min_samples_split': randint(2, 10),   # Minimum samples to split a node\n",
    "            'min_samples_leaf': randint(1, 10)     # Minimum samples in a leaf\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'C': uniform(0.1, 10.0),       # Regularization parameter\n",
    "            'kernel': ['linear', 'rbf'],   # Kernel type\n",
    "            'gamma': ['scale', 'auto']     # Kernel coefficient\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': randint(3, 20),     # Number of neighbors\n",
    "            'weights': ['uniform', 'distance']  # Weight function\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# List to store model comparison results\n",
    "results = []\n",
    "\n",
    "# Iterate over each model, perform RandomizedSearchCV, and evaluate\n",
    "for model_name, config in models.items():\n",
    "    print(f\"Training and tuning {model_name}...\")\n",
    "    \n",
    "    # Perform RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=config['model'],\n",
    "        param_distributions=config['params'],\n",
    "        n_iter=50,                # Number of parameter settings sampled\n",
    "        cv=5,                     # 5-fold cross-validation\n",
    "        scoring='accuracy',       # Use accuracy as the scoring metric\n",
    "        random_state=42,\n",
    "        verbose=0                 # Suppress verbose output\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model and its parameters\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Best Parameters for {model_name}: {best_params}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1-score: {f1:.4f}\")\n",
    "    \n",
    "    # Store results for comparison\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Best Model': best_model,\n",
    "        'Best Parameters': best_params,\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Create a DataFrame to summarize results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nComparison of Models:\")\n",
    "print(results_df)\n",
    "\n",
    "# Select the best model based on accuracy\n",
    "best_result = max(results, key=lambda x: x['Accuracy'])\n",
    "best_model_name = best_result['Model']\n",
    "best_model = best_result['Best Model']\n",
    "best_params = best_result['Best Parameters']\n",
    "best_accuracy = best_result['Accuracy']\n",
    "best_f1 = best_result['F1 Score']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_accuracy:.4f}, F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "# Log the best model to MLflow\n",
    "mlflow.set_experiment(\"Forest Fire Best Model\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"Best_Model_{best_model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "    # Log best model parameters and metrics\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"accuracy\", best_accuracy)\n",
    "    mlflow.log_metric(\"f1_score\", best_f1)\n",
    "    mlflow.set_tag(\"Model\", best_model_name)\n",
    "    \n",
    "    # Log the best model with signature and input example\n",
    "    signature = infer_signature(X_train, best_model.predict(X_train))\n",
    "    input_example = X_train[:5]\n",
    "    \n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=best_model,\n",
    "        artifact_path=f\"{best_model_name}_model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=\"Forest_Fire_Best_Model\"\n",
    "    )\n",
    "\n",
    "print(\"\\nBest model logged to MLflow successfully!\")\n",
    "\n",
    "with open('model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(lr, model_file)\n",
    "\n",
    "with open('model.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3359c74f-c15a-4c88-8389-d6cab330dcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7745df-7cfc-461a-b2ea-4813ba823aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
